/************************************************************************* 
 *                                  
 *  Project               
 *                        __  __ _______ _____  _  __
 *                       |  \/  |__   __|  __ \| |/ /
 *  ___  _ __   ___ _ __ | \  / |  | |  | |__) | ' / 
 * / _ \| '_ \ / _ \ '_ \| |\/| |  | |  |  ___/|  <  
 *| (_) | |_) |  __/ | | | |  | |  | |  | |    | . \ 
 * \___/| .__/ \___|_| |_|_|  |_|  |_|  |_|    |_|\_\  
 *      | |                                          
 *      |_|                                         
 *
 *
 * Copyright (C) Akiel Aries, <akiel@akiel.org>.
 *
 * This software is licensed as described in the file LICENSE, which
 * you should have received as part of this distribution. The terms
 * among other details are referenced in the official documentation
 * seen here : https://akielaries.github.io/openMTPK/ along with 
 * important files seen in this project.
 *
 * You may opt to use, copy, modify, merge, publish, distribute 
 * and/or sell copies of the Software, and permit persons to whom 
 * the Software is furnished to do so, under the terms of the 
 * LICENSE file. As this is an Open Source effort, all implementations
 * must be of the same methodology.
 * 
 * This software emphasize *'Do No Harm'* in all applications.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT 
 * WARRANTY OF ANY KIND, either express or implied.
 *
 ************************************************************************/

/*
 * testing our implemented k-fold cross-validation
 */

#include "k-foldCV.h"
using namespace std;

TEST_CASE("KF_CV-testSmallSample10Fold") {
    vector<string> small_sample = {"1", "2", "3", "4", "5",
                                   "6", "7", "8", "9", "10"};
    KF_CV<string> kF_CV = KF_CV<string>(smallSample, 10, 1);
    vector<string> test_sample = kF_CV.get_test_fold(0);
    REQUIRE(test_sample[0] == "2");
}

TEST_CASE("KF_CV-testSmallSample5Fold") {
    vector<string> small_sample = {"1", "2", "3", "4", "5",
                                   "6", "7", "8", "9", "10"};
    KF_CV<string> kF_CV = KF_CV<string>(small_sample, 5, 1);
    vector<string> test_sample = kF_CV.get_test_fold(0);
    REQUIRE(test_sample[0] == "2");
    REQUIRE(test_sample[1] == "7");
}

TEST_CASE("KF_CV-testLargeSample10Fold") {
    vector<int64_t> large_sample;
    for (int64_t i = 0; i < 1000; i++) {
        large_sample.emplace_back(i);
    }
    KF_CV<int64_t> kF_CV = KF_CV<int64_t>(large_sample, 10, 1);
    for (int64_t i = 0; i < 10; i++) {
        REQUIRE(100 == kF_CV.get_test_fold(i).size());
        REQUIRE(900 == kF_CV.get_train_fold(i).size());
    }
}

TEST_CASE("KFCV-testLargeSample5Fold") {
    vector<int64_t> large_sample;
    for (int64_t i = 0; i < 1000; i++) {
        large_sample.emplace_back(i);
    }
    KF_CV<int64_t> kF_CV = KF_CV<int64_t>(large_sample, 5, 1);
    for (int64_t i = 0; i < 5; i++) {
        REQUIRE(200 == kF_CV.get_test_fold(i).size());
        REQUIRE(800 == kF_CV.get_train_fold(i).size());
    }
}
/*
 * taking a look at implementing regression in c++
 */
#include "../../include/ml/linreg.hpp"
#include <fstream>
#include <iostream>
#include <stdio.h>
#include <string>
#include <vector>

/*
 * Constructor to provide the default values to all the terms in the
 * object of class regression
 */
mtpk::LinearRegression::LinearRegression() {
    coeff = 0;
    constant = 0;
    sum_y = 0;
    sum_y_square = 0;
    sum_x_square = 0;
    sum_x = 0;
    sum_xy = 0;
}

// Function that calculate the coefficient/slope of the best fitting
// line
void mtpk::LinearRegression::calculate_coeffecient() {
    long double N = x.size();
    long double numerator = (N * sum_xy - sum_x * sum_y);
    long double denominator = (N * sum_x_square - sum_x * sum_x);
    coeff = numerator / denominator;
}

/*
 * Member function that will calculate the constant term of the best
 * fitting line
 */
void mtpk::LinearRegression::calculate_constant() {
    long double N = x.size();
    long double numerator = (sum_y * sum_x_square - sum_x * sum_xy);
    long double denominator = (N * sum_x_square - sum_x * sum_x);
    constant = numerator / denominator;
}

// Function that return the number of entries (xi, yi) in the data set
int64_t mtpk::LinearRegression::data_size() {
    return x.size();
}

// Function that return the coefficient/slope of the best fitting line
long double mtpk::LinearRegression::return_coeffecient() {
    if (coeff == 0)
        calculate_coeffecient();
    return coeff;
}

// Function that return the constant term of the best fitting line
long double mtpk::LinearRegression::return_constant() {
    if (constant == 0)
        calculate_constant();
    return constant;
}

// Function that print the best fitting line
void mtpk::LinearRegression::best_fit() {
    if (coeff == 0 && constant == 0) {
        calculate_coeffecient();
        calculate_constant();
    }
    std::cout << "The best fitting line is y = " << coeff << "x + "
              << constant << std::endl;
}

// Function to take input from the dataset
void mtpk::LinearRegression::get_input(int64_t n) {
    for (int64_t i = 0; i < n; i++) {
        /*
         * In a csv file all the values of xi and yi are separated by
         * commas
         */
        char comma;
        long double xi;
        long double yi;
        std::cin >> xi >> comma >> yi;
        sum_xy += xi * yi;
        sum_x += xi;
        sum_y += yi;
        sum_x_square += xi * xi;
        sum_y_square += yi * yi;
        x.push_back(xi);
        y.push_back(yi);
    }
}

// Function to show the data set
void mtpk::LinearRegression::show_data() {
    for (int64_t i = 0; i < 62; i++) {
        printf("_");
    }
    printf("\n\n");
    printf("|%15s%5s %15s%5s%20s\n", "X", "", "Y", "", "|");

    for (int64_t i = 0; uint64_t(i) < x.size(); i++) {
        printf("|%20Lf %20Lf%20s\n", x[i], y[i], "|");
    }

    for (int64_t i = 0; i < 62; i++) {
        printf("_");
    }
    printf("\n");
}

// Function to predict the value corresponding to some input
long double mtpk::LinearRegression::predict(long double x) {
    return coeff * x + constant;
}

// Function that returns overall sum of square of errors
long double mtpk::LinearRegression::error_square() {
    long double ans = 0;
    for (int64_t i = 0; uint64_t(i) < x.size(); i++) {
        ans += ((predict(x[i]) - y[i]) * (predict(x[i]) - y[i]));
    }
    return ans;
}
/*
 * Functions that return the error i.e the difference between the
 * actual value and value predicted by our model
 */
long double mtpk::LinearRegression::error_in(long double num) {
    for (int64_t i = 0; uint64_t(i) < x.size(); i++) {
        if (num == x[i]) {
            return (y[i] - predict(x[i]));
        }
    }
    return 0;
}

int64_t mtpk::LinearRegression::num_rows(const char *input) {
    int64_t num = 0;
    std::string row;

    // create input file stream
    std::ifstream file(input);

    while (getline(file, row)) {
        num++;
    }

    return num;
}
/*
int num_col(const char* input) {
    int num = 0;
    string col;
    std::ifstream file(input);

    return col;

}
*/
/************************************************************************* 
 *                                  
 *  Project               
 *                        __  __ _______ _____  _  __
 *                       |  \/  |__   __|  __ \| |/ /
 *  ___  _ __   ___ _ __ | \  / |  | |  | |__) | ' / 
 * / _ \| '_ \ / _ \ '_ \| |\/| |  | |  |  ___/|  <  
 *| (_) | |_) |  __/ | | | |  | |  | |  | |    | . \ 
 * \___/| .__/ \___|_| |_|_|  |_|  |_|  |_|    |_|\_\  
 *      | |                                          
 *      |_|                                         
 *
 *
 * Copyright (C) Akiel Aries, <akiel@akiel.org>.
 *
 * This software is licensed as described in the file LICENSE, which
 * you should have received as part of this distribution. The terms
 * among other details are referenced in the official documentation
 * seen here : https://akielaries.github.io/openMTPK/ along with 
 * important files seen in this project.
 *
 * You may opt to use, copy, modify, merge, publish, distribute 
 * and/or sell copies of the Software, and permit persons to whom 
 * the Software is furnished to do so, under the terms of the 
 * LICENSE file. As this is an Open Source effort, all implementations
 * must be of the same methodology.
 * 
 * This software emphasize *'Do No Harm'* in all applications.
 *
 * This software is distributed on an "AS IS" basis, WITHOUT 
 * WARRANTY OF ANY KIND, either express or implied.
 *
 ************************************************************************/

/*
 * Implementation of a Multi-Layered Perceptron Neural Network
 */
#include "../../include/ml/mlp_net.hpp"
#include <math.h>
#include <stdio.h>
#include <string.h>
#include <time.h>

using namespace mtpk::ml;

/*
 * Initialize randomly generated values for network's method
 */
void mtpk::ml::PrimaryMLP::rand_init() {
    srand(4711);
    // srand((uint64_t)time(NULL));
}

/* verify the random is an integer */
int64_t mtpk::ml::PrimaryMLP::rand_int(int64_t hi, int64_t low) {
    return rand() % (hi - low + 1) + low;
}

/* verify generated random is a real number */
long double mtpk::ml::PrimaryMLP::rand_real(long double low,
                                            long double hi) {
    return ((long double)rand() / RAND_MAX) * (hi - low) + low;
}

/* PRIMARY MLP CONSTRUCTOR */
mtpk::ml::PrimaryMLP::PrimaryMLP(int64_t nl, int64_t npl[])
    : num_layers(0), layer_ptr(0), _MSE(0.0), _MAE(0.0), _Eta(0.25),
      _Alpha(0.9), _Gain(1.0), _AvgTestError(0.0) {
    int64_t _LAYER, _NEURON;

    // create network layers
    num_layers = nl;
    layer_ptr = new layer[nl];

    // intialize the data of the created network layers
    for (_LAYER = 0; _LAYER < nl; _LAYER++) {
        // intialize values to neuron struct information
        layer_ptr[_LAYER].num_neurons = npl[_LAYER];
        layer_ptr[_LAYER].neuron_ptr = new neuron[npl[_LAYER]];

        // intialize date of the neurons of the created network layers
        for (_NEURON = 0; _NEURON < npl[_LAYER]; _NEURON++) {
            // initialize exit value
            layer_ptr[_LAYER].neuron_ptr[_NEURON].sortir = 1.0;
            // save the error
            layer_ptr[_LAYER].neuron_ptr[_NEURON].err = 0.0;

            // check if there is at least 1 layer
            if (_LAYER > 0) {
                /* initialize weight, last weight, and saved weight
                 * values to _LAYER - 1
                 */
                layer_ptr[_LAYER].neuron_ptr[_NEURON].wt =
                    new long double[npl[_LAYER - 1]];

                layer_ptr[_LAYER].neuron_ptr[_NEURON].wt_last =
                    new long double[npl[_LAYER - 1]];

                layer_ptr[_LAYER].neuron_ptr[_NEURON].wt_saved =
                    new long double[npl[_LAYER - 1]];
            }
            // otherwise
            else {
                /*
                 * initialize weight, last weight, and saved weight
                 * to NULL
                 */
                layer_ptr[_LAYER].neuron_ptr[_NEURON].wt = NULL;
                layer_ptr[_LAYER].neuron_ptr[_NEURON].wt_last = NULL;
                layer_ptr[_LAYER].neuron_ptr[_NEURON].wt_saved = NULL;
            }
        }
    }
}

/* PRIMARY MLP DECONSTRUCTOR */
mtpk::ml::PrimaryMLP::~PrimaryMLP() {
    int64_t _LAYER, _NEURON;

    // TODO : thread the loops dealing with rudimentary computations

    for (_LAYER = 0; _LAYER < num_layers; _LAYER++) {
        if (layer_ptr[_LAYER].neuron_ptr) {
            for (_NEURON = 0; _NEURON < layer_ptr[_LAYER].num_neurons;
                 _NEURON++) {
                if (layer_ptr[_LAYER].neuron_ptr[_NEURON].wt) {
                    delete[] layer_ptr[_LAYER].neuron_ptr[_NEURON].wt;
                }

                if (layer_ptr[_LAYER].neuron_ptr[_NEURON].wt_last) {
                    delete[] layer_ptr[_LAYER].neuron_ptr[_NEURON].wt_last;
                }

                if (layer_ptr[_LAYER].neuron_ptr[_NEURON].wt_saved) {
                    delete[] layer_ptr[_LAYER]
                        .neuron_ptr[_NEURON]
                        .wt_saved;
                }
            }
        }
        delete[] layer_ptr[_LAYER].neuron_ptr;
    }
    delete[] layer_ptr;
}
/*
 * Implementation of a standard or naive neural network
 */
#include "../../include/ml/naive_network.hpp"
#include "../../include/linalg/matrices.hpp"
#include "k-NN.h"
#include <algorithm>
#include <fstream>
#include <iostream>
#include <string>
#include <vector>

using namespace std;

/*
 * For this particular exmaple this is a class which contains the
 * turnover and success of a company and the characteristics of the
 * team. The file with the data will be a csv file whit 3 columns:
 *   - turover(int)
 *   - characteristics(unsigned)
 *   - success(boolean)
 */
class Company {
    public:
    Company(int64_t turnover, string characteristics, bool success)
        : turnover(turnover), success(success), distance(-1) {
        this->characteristics = transformCharacteristics(characteristics);
    }

    // distance from test point
    double distance;
    int64_t turnover;
    int64_t characteristics;
    bool success;

    private:
    /*
     * Function that transforms characteristics (Very
     * Strong,Strong,Average,Weak) as strings to number. It is geting
     * the ASCII code as decimal number and retuning the total sum of
     * all characters within the string.
     */
    int64_t transformCharacteristics(string &c) {
        uint64_t sum = 0;
        for (size_t i = 0; i < c.size(); ++i) {
            if (c[i] != ' ') {
                sum += (int64_t)c[i];
            }
        }
        return sum;
    }
};

/*
 * A class that represent the reader of files with csv extensions.
 */
class CSVReader {
    public:
    CSVReader(const string &fileName, const string &delimeter = ",")
        : fileName(fileName), delimeter(delimeter) {
    }

    /*
     * Function to fetch the data from a CSV file
     */
    vector<vector<string>> getData() {
        ifstream file(this->fileName);
        vector<vector<string>> data;
        string line = "";

        while (getline(file, line)) {
            vector<string> tmp;
            tmp = this->split(line, ",");
            data.push_back(tmp);
        }
        file.close();
        return data;
    }

    private:
    string fileName;
    string delimeter;

    /*
     * Function used to split each line by the delim
     */
    vector<string> split(string target, string delim) {
        vector<string> v;
        if (!target.empty()) {
            size_t start = 0;
            do {
                size_t x = target.find(delim, start);
                // a check whether the target is found
                if (x == -1) {
                    break;
                }
                string tmp = target.substr(start, x - start);
                v.push_back(tmp);
                start += delim.size() + tmp.size();
            } while (true);

            v.push_back(target.substr(start));
        }
        return v;
    }
};

// function used to compare two companies when sorting
bool comparison(Company &lhs, Company &rhs) {
    return lhs.distance < rhs.distance;
}

long double euclideanDistance(Company &lhs, Company &test) {
    return sqrt(pow((lhs.turnover - test.turnover), 2) +
                pow((lhs.characteristics - test.characteristics), 2));
}

long double manhattanDistance(Company &lhs, Company &test) {
    return (abs(lhs.turnover - test.turnover) +
            abs(lhs.characteristics - test.characteristics));
}

void fillDistances(vector<Company> &data, Company &test,
                   double (*distanceFunction)(Company &, Company &)) {
    for (size_t i = 0; i < data.size(); ++i) {
        data[i].distance = distanceFunction(data[i], test);
    }
}

bool KNN(vector<Company> &data, Company &test, int k,
         double (*distanceFunction)(Company &, Company &)) {
    // filling the distances between all points and test
    fillDistances(data, test, distanceFunction);

    // sorting so that we can get the k nearest
    sort(data.begin(), data.end(), comparison);

    int64_t countSuccesful = 0;
    int64_t countUnsuccesful = 0;
    for (int64_t i = 0; i < k; ++i) {
        if (data[i].success) {
            ++countSuccesful;
        } else {
            ++countUnsuccesful;
        }
    }
    /*
     * Based on the count of succesful and unsuccessful examples
     * within those k, we are deciding whether the test example is
     * successful or not.
     */
    if (countSuccesful == countUnsuccesful) {
        test.success = data[0].success;
    } else {
        test.success = countSuccesful > countUnsuccesful ? true : false;
    }
    return test.success;
}

int main() {
    const string path = "../data/zip.test.gz";
    CSVReader reader(path);
    vector<vector<string>> rawData = reader.getData();
    vector<Company> data;
    for (vector<string> line : rawData) {
        Company comp(stoi(line[0]), line[1],
                     line[2] == "1" ? true : false);
        data.push_back(comp);
    }

    /* Test examples
     * 1256 Weak - should return Successful
     * 725 Weak - should return Unsuccessful
     * 1471 Average - should return Successful
     * 703 Very Strong - should return Unsuccessful
     * 1301 Strong - should return Successful
     */
    Company test(703, "Very Strong", true);

    string answer = KNN(data, test, 12, euclideanDistance)
                        ? "Successful"
                        : "Unsuccessful";
    cout << answer;
}
